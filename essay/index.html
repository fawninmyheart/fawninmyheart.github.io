<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">
<link rel="stylesheet" href="/css/me.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.fawninmyheart.top","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="随手记录学到的知识点  谚语一脚踩在狗屎上，一滑滑成大会员：形容走了狗屎运  生信 正常机体就会通过选择性剪接产生各种提前出现的密码子转录本来调节基因的表达量。因此密码子通读这种疗法有一个缺陷，它不是靶向的，所有提前出现的终止密码子都有概率被通读，会干扰正常的基因表达调控。   nginx网站打开问题可以查看nginx的报错日志：cat &#x2F;var&#x2F;log&#x2F;nginx">
<meta property="og:type" content="website">
<meta property="og:title" content="You are my sunshine&lt;br&gt;being with you is like walking on a clear morning">
<meta property="og:url" content="https://www.fawninmyheart.top/essay/index.html">
<meta property="og:site_name" content="You are my sunshine&lt;br&gt;being with you is like walking on a clear morning">
<meta property="og:description" content="随手记录学到的知识点  谚语一脚踩在狗屎上，一滑滑成大会员：形容走了狗屎运  生信 正常机体就会通过选择性剪接产生各种提前出现的密码子转录本来调节基因的表达量。因此密码子通读这种疗法有一个缺陷，它不是靶向的，所有提前出现的终止密码子都有概率被通读，会干扰正常的基因表达调控。   nginx网站打开问题可以查看nginx的报错日志：cat &#x2F;var&#x2F;log&#x2F;nginx">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.fawninmyheart.top/essay/%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF.jpg">
<meta property="og:image" content="https://www.fawninmyheart.top/essay/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.jpg">
<meta property="og:image" content="https://www.fawninmyheart.top/essay/MobileNetV2%E6%9E%B6%E6%9E%84.jpg">
<meta property="og:image" content="https://www.fawninmyheart.top/essay/MobileNetV3%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png">
<meta property="og:image" content="https://www.fawninmyheart.top/essay/MobileNetV3-Large%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png">
<meta property="og:image" content="https://www.fawninmyheart.top/essay/MobileNetV3-small%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png">
<meta property="og:image" content="https://www.fawninmyheart.top/essay/MobileNetV3%E7%9A%84bneck%E7%BB%93%E6%9E%84.png">
<meta property="og:image" content="https://www.fawninmyheart.top/essay/%E6%80%A7%E8%83%BD%E6%AF%94%E8%BE%83.png">
<meta property="og:image" content="https://www.fawninmyheart.top/essay/Cifar-10.png">
<meta property="og:image" content="https://www.fawninmyheart.top/essay/%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C.png">
<meta property="article:published_time" content="2024-07-18T01:28:20.000Z">
<meta property="article:modified_time" content="2024-09-12T09:54:01.088Z">
<meta property="article:author" content="Shen Hua">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.fawninmyheart.top/essay/%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF.jpg">

<link rel="canonical" href="https://www.fawninmyheart.top/essay/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title></title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="You are my sunshine<br>being with you is like walking on a clear morning" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <me class="site-title">You are my sunshine<br>being with you is like walking on a clear morning</me>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-sketch">

    <a href="/sketch/" rel="section"><i class="fa fa-pen fa-fw"></i>素描</a>

  </li>
        <li class="menu-item menu-item-travel">

    <a href="/travel/" rel="section"><i class="fa fa-mountain fa-fw"></i>旅行</a>

  </li>
        <li class="menu-item menu-item-essay">

    <a href="/essay/" rel="section"><i class="fa fa-comment fa-fw"></i>杂记</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
  
  

          <div class="content page posts-expand">
            

    
    
    
    <div class="post-block" lang="zh-CN">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">
</h1>

<div class="post-meta">
  

</div>

</header>

      
      
      
      <div class="post-body">
          <hr>
<p>随手记录学到的知识点</p>
<hr>
<h3 id="谚语"><a href="#谚语" class="headerlink" title="谚语"></a>谚语</h3><p>一脚踩在狗屎上，一滑滑成大会员：形容走了狗屎运</p>
<hr>
<h3 id="生信"><a href="#生信" class="headerlink" title="生信"></a>生信</h3><ol>
<li>正常机体就会通过选择性剪接产生各种提前出现的密码子转录本来调节基因的表达量。因此密码子通读这种疗法有一个缺陷，它不是靶向的，所有提前出现的终止密码子都有概率被通读，会干扰正常的基因表达调控。</li>
</ol>
<hr>
<h3 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h3><p>网站打开问题可以查看nginx的报错日志：cat &#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log</p>
<hr>
<h3 id="snakemake"><a href="#snakemake" class="headerlink" title="snakemake"></a>snakemake</h3><h4 id="BUG"><a href="#BUG" class="headerlink" title="BUG"></a>BUG</h4><ol>
<li>使用lambda函数从字典中获取rule的input时，随机出现Keyerror错误。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sampleInfo = &#123;</span><br><span class="line">    <span class="string">&quot;ID01&quot;</span>: &#123;<span class="string">&quot;3&quot;</span>:<span class="string">&quot;ID01.R1.fa&quot;</span>, <span class="string">&quot;5&quot;</span>:<span class="string">&quot;ID01.R2.fa&quot;</span>&#125;,</span><br><span class="line">    <span class="string">&quot;ID02&quot;</span>: &#123;<span class="string">&quot;3&quot;</span>:<span class="string">&quot;ID02.R1.fa&quot;</span>, <span class="string">&quot;5&quot;</span>:<span class="string">&quot;ID02.R2.fa&quot;</span>&#125;,</span><br><span class="line">    ...</span><br><span class="line">    <span class="string">&quot;ID20&quot;</span>: &#123;<span class="string">&quot;3&quot;</span>:<span class="string">&quot;ID20.R1.fa&quot;</span>, <span class="string">&quot;5&quot;</span>:<span class="string">&quot;ID20.R2.fa&quot;</span>&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rule <span class="built_in">test</span>:</span><br><span class="line">    input:</span><br><span class="line">        ab1_file_L3 = lambda wildcards: sampleInfo[wildcards.sid][<span class="string">&quot;3&quot;</span>],</span><br><span class="line">        ab1_file_L5 = lambda wildcards: sampleInfo[wildcards.sid][<span class="string">&quot;5&quot;</span>]</span><br></pre></td></tr></table></figure>
猜想1：snakemake检测input使用了多线程，导致偶发性的多线程冲突。<br>尝试修改：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def ab1_dict_from_sample(wildcards):</span><br><span class="line">    <span class="built_in">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;ab1_file_L3&quot;</span>: sampleInfo[wildcards.sid][<span class="string">&quot;3&quot;</span>],</span><br><span class="line">        <span class="string">&quot;ab1_file_L5&quot;</span>: sampleInfo[wildcards.sid][<span class="string">&quot;5&quot;</span>]</span><br><span class="line">    &#125;</span><br><span class="line">rule <span class="built_in">test</span>:</span><br><span class="line">    input:</span><br><span class="line">        unpack(ab1_dict_from_sample)</span><br></pre></td></tr></table></figure>
运行一段时间看看还会不会有出现这个错误（2024.9.2）。<br><strong>↑ 没效果（2024.9.6）</strong><br>重新设计了解决方法，尝试使用try重复获取发生了错误的Key（2024.9.9）：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">def ab1_dict_from_sample(wildcards, count = 0):</span><br><span class="line">    <span class="keyword">if</span> count == 10:</span><br><span class="line">        <span class="built_in">return</span> &#123;</span><br><span class="line">            <span class="string">&quot;ab1_file_L3&quot;</span>: sampleInfo[wildcards.sid][<span class="string">&quot;3&quot;</span>],</span><br><span class="line">            <span class="string">&quot;ab1_file_L5&quot;</span>: sampleInfo[wildcards.sid][<span class="string">&quot;5&quot;</span>]</span><br><span class="line">        &#125;</span><br><span class="line">    try:</span><br><span class="line">        getData = &#123;</span><br><span class="line">            <span class="string">&quot;ab1_file_L3&quot;</span>: sampleInfo[wildcards.sid][<span class="string">&quot;3&quot;</span>],</span><br><span class="line">            <span class="string">&quot;ab1_file_L5&quot;</span>: sampleInfo[wildcards.sid][<span class="string">&quot;5&quot;</span>]</span><br><span class="line">        &#125;</span><br><span class="line">    except KeyError:</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&quot;show sampleID:&quot;</span>, sampleInfo.keys())</span><br><span class="line">        time.sleep(3)</span><br><span class="line">        count += 1</span><br><span class="line">        getData = ab1_dict_from_sample(wildcards, count)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">return</span> getData</span><br><span class="line">rule <span class="built_in">test</span>:</span><br><span class="line">    input:</span><br><span class="line">        unpack(ab1_dict_from_sample)</span><br></pre></td></tr></table></figure>
<strong>↑ 没效果（2024.9.12）</strong><br>但是明确了一点：发生错误的键值对的确从sampleInfo中被删除了，因此决定将sampleInfo转为静态变量（2023.9.13）<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import types</span><br><span class="line">sampleInfo = types.MappingProxyType(sampleInfo)</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h3 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h3><h4 id="commit-message-规范"><a href="#commit-message-规范" class="headerlink" title="commit message 规范"></a>commit message 规范</h4><p>commit message包含三部分：Header,Body和Footer</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="built_in">type</span>&gt;(&lt;scope&gt;): &lt;subject&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;footer&gt;</span><br></pre></td></tr></table></figure>
<p>Header是必需的，Body和Footer则可以省略</p>
<h5 id="Header"><a href="#Header" class="headerlink" title="Header"></a>Header</h5><ol>
<li>type（必需）<br>用于说明git commit的类别，允许使用下面几个标识。<br><code>feat</code>：新功能<br><code>fix/to</code>：bug修复。to指部分修复，fix指完全修复。<br><code>docs</code>：修改附属文档。<br><code>style</code>：调整了代码书写格式，不影响代码运行。<br><code>refactor</code>：代码重构。<br><code>perf</code>：性能优化<br><code>test</code>：增加测试<br><code>chore</code>：构建过程或辅助工具的变动<br><code>revert</code>：回滚<br><code>merge</code>：代码合并<br><code>sync</code>：同步主线或分支的 Bug，通常用于解决因为合并而引入的问题。</li>
</ol>
<h5 id="Git-commit工具"><a href="#Git-commit工具" class="headerlink" title="Git commit工具"></a>Git commit工具</h5><ol>
<li><p><a target="_blank" rel="noopener" href="https://github.com/commitizen/cz-cli">Commitizen</a><br>用于撰写合格的Git提交信息。<br>首先，全局安装Commitizen:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">su -</span><br><span class="line">npm install -g commitizen</span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure>
<p>然后，在项目目录中运行下方命令，使文件夹支持Angular规范的Commit message。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">commitizen init cz-conventional-changelog --save --save-exact</span><br></pre></td></tr></table></figure>
<p>需要提交修改时，使用<code>git cz</code>替换<code>git commit</code>，可以打开Commitizen的引导界面。在这个交互式界面中，你可以选择提交的类型（feat、fix、docs 等）、影响的范围（scope）、简短的描述（subject）以及其他相关信息。</p>
</li>
<li><p>vscode插件（git-commit-plugin）<br>支持emoji表情</p>
</li>
</ol>
<hr>
<h3 id="图像去重、人物识别、系列图片分组"><a href="#图像去重、人物识别、系列图片分组" class="headerlink" title="图像去重、人物识别、系列图片分组"></a>图像去重、人物识别、系列图片分组</h3><h4 id="图片去重"><a href="#图片去重" class="headerlink" title="图片去重"></a>图片去重</h4><p>可以使用<a target="_blank" rel="noopener" href="https://github.com/idealo/imagededup">imagededup</a>。</p>
<h4 id="人物识别"><a href="#人物识别" class="headerlink" title="人物识别"></a>人物识别</h4><p>不只是最简单的面部识别，还需要解决面部缺失时的识别问题。</p>
<h5 id="研究方向"><a href="#研究方向" class="headerlink" title="研究方向"></a>研究方向</h5><ol>
<li>将皮肤特征经过标准化转换后投影成一个image。每个像素对应了一块皮肤特征，分辨率由这块皮肤大小决定。每个像素包含了皮肤的斑纹特征。同时，由于经过了标准化转换，因此每个像素中还包含了比例信息。直观地说，就是根据图片集构建了对象皮肤特征的三维模型，将三维模型不等比缩放成标准人体模型大小，最后转为二维化保存。<br>由照片生成三位模型的时候必需考虑到阴影、妆容、服装对皮肤斑纹特征和人体形状的影响。</li>
</ol>
<h4 id="系列图片分组"><a href="#系列图片分组" class="headerlink" title="系列图片分组"></a>系列图片分组</h4><p>根据人物识别、背景、服装等条件，对图片进行归类分组。</p>
<h4 id="MobileNet"><a href="#MobileNet" class="headerlink" title="MobileNet"></a>MobileNet</h4><p>MobileNet（出自论文MobileNets：Efficient Convolutional Neural Networks for Mobile Vision Applications）是轻量化模型中的经典网络。传统卷积神经网络的内容需求大、运算量大、无法在移动设备和嵌入式设备上运行。在此基础上，Google针对手机等嵌入式设备提出了MobileNet，一种轻量化深度神经网络，其核心思想是深度可分离卷积（Depthwise Separable Convolution）。目前，MobileNet在移动端图像分类、目标检测、语义分割等任务上均取得了优秀的表现。</p>
<blockquote>
<p><a href="/essay/MobileNetsV1.pdf">MobileNetV1论文</a>: <a href="/MobileNetsV1/index.html">阅读笔记</a><br><a href="/essay/MobileNetsV3.pdf">MobileNetV3论文</a><br>MobileNetV3采用了很多新的技术，包括针对通道注意力的Squeeze-and-Excitation模块、NAS搜索方法等，这些方法都有利于进一步提升网络的性能。</p>
</blockquote>
<h5 id="MobileNet发展史"><a href="#MobileNet发展史" class="headerlink" title="MobileNet发展史"></a>MobileNet发展史</h5><ol>
<li><p>MobileNet V1<br>MobileNet V1是由Google在2016年提出的，其主要创新点在于深度卷积(Depthwise Convolution)，而整个网络实际上也是深度可分离模块的堆叠。<br>深度可分离卷积是MobileNet的基本单元，其实这种结构之前已经在Inception模型中使用了。深度可分离卷积其实是一种可分解卷积操作，该操作也可以分解为两个更小的卷积操作：深度卷积和逐点卷积(Pointwise Convolution)，如图所示。<br><img src="/essay/%E6%B7%B1%E5%BA%A6%E5%8F%AF%E5%88%86%E7%A6%BB%E5%8D%B7%E7%A7%AF.jpg" alt="图片加载失败"><br>深度卷积与标准卷积不同。对于标准卷积，其卷积核用在所有输入通道(Input Channel)上，而深度卷积针对每个输入通道采用不同的卷积核，即一个卷积核对应一个输入通道。所以说深度卷积是逐通道的操作，而逐点卷积其实就是普通的1×1卷积。<br>对于深度可分离卷积，首先采用深度卷积对不同的输入通道分别进行卷积，然后采用逐点卷积将上面的输出进行结合。这样做的整体效果与一个标准卷积是差不多的，但是会大大减少计算量和模型参数量。<br>MobileNet V1，存在以下两个问题:<br>a) MobileNet V1的结构过于简单，没有复用图像特征，即没有Concat或Add等操作进行特征融合，而后续一系列的ResNet、DenseNet等结构已经证明复用图像特征的有效性。<br>b) 深度可分离卷积问题。在处理低维数据时，ReLU激活函数会造成信息的丢失。深度可分离卷积由于本身的计算特性决定了它本身没有改变通道数的能力，上一层给它多少通道，它就只能输出多少通道。因此，如果上一层给它的通道很少，那么它也只能使用在低维空间提取到的一些Low-Level特征，这可能会带来性能问题。<br>为了解决上述问题，MobileNet V2应运而生。</p>
</li>
<li><p>MobileNet V2<br>对于深度可分离卷积中的第2个激活函数，在MobileNet V2中修改为“线性激活”，论文中称其为“Linear Bottleneck”。论文作者认为ReLU激活函数在高维空间能够有效提升MobileNet V2的非线性；而在低维空间则会破坏特征、损失特征的信息，性能可能并不如线性激活函数好。<br>如图，对于结构设计问题，MobileNet V2在MobileNet V1的Block&#x3D;&#x3D;＞卷积模块中的深度可分离卷积前增加了一个逐点卷积（1×1卷积+BN+ReLU6），专门用来提升特征的维度，这样便可以得到High-Level特征，从而提升模型的性能。<br><img src="/essay/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0.jpg" alt="图片加载失败"><br>MobileNet V2同样借鉴了ResNet，采用了残差结构，将输出与输入相加，但是ResNet中的残差结构是先降维卷积再升维，而MobileNet V2则是先升维卷积再降维。<br>ResNet的残差结构更像一个沙漏，而MobileNet V2中的残差结构则更像是一个纺锤，两者刚好相反。因此论文作者将MobileNet V2的结构称为“Inverted Residual Block”。为了解决深度卷积的局限问题，特征提取能够在高维进行。<br><img src="/essay/MobileNetV2%E6%9E%B6%E6%9E%84.jpg" alt="图片加载失败"><br>上图为MobileNet V2的整体架构。</p>
</li>
<li><p>MobileNet V3<br>MobileNetV3的整体架构基本沿用了MobileNetV2的设计，采用了轻量级的深度可分离卷积和残差块等结构，依然是由多个模块组成，但是每个模块得到了优化和升级，包括瓶颈结构、SE模块和NL模块。MobileNetV3在ImageNet 分类任务中正确率上升了 3.2%，计算延时还降低了20%。<br>整体来说MobileNetV3有两大创新点：<br>a) 互补搜索技术组合：由资源受限的NAS执行模块级搜索，NetAdapt执行局部搜索。<br>b) 网络结构改进：将最后一步的平均池化层前移并移除最后一个卷积层，引入h-swish激活函数。<br>MobileNetV3 有两个版本，MobileNetV3-Small 与 MobileNetV3-Large 分别对应对计算和存储要求低和高的版本。<br>这是论文中给出的网络结构，值得注意的是第一个卷积核的个数为16，并且采用了HS激活函数；表中exp_size代表benck中第一部分升维后的channel，SE代表是否使用SE模块，NL表示激活函数的类型，HS代表hard-swish激活函数，RE代表ReLU激活函数，s代表步长。<br><img src="/essay/MobileNetV3%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png" alt="图片加载失败"><br>1）MobileNetV3-Large的网络结构：<br><img src="/essay/MobileNetV3-Large%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png" alt="图片加载失败"><br>2）MobileNetV3-Small的网络结构：<br><img src="/essay/MobileNetV3-small%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png" alt="图片加载失败"><br>3）MobileNetV3特有的bneck结构：<br><img src="/essay/MobileNetV3%E7%9A%84bneck%E7%BB%93%E6%9E%84.png" alt="图片加载失败"></p>
</li>
</ol>
<h5 id="MobileNet模型比较"><a href="#MobileNet模型比较" class="headerlink" title="MobileNet模型比较"></a>MobileNet模型比较</h5><p><img src="/essay/%E6%80%A7%E8%83%BD%E6%AF%94%E8%BE%83.png" alt="图片加载失败"></p>
<h5 id="MobileNetV3在CIFAR10数据集上的实现"><a href="#MobileNetV3在CIFAR10数据集上的实现" class="headerlink" title="MobileNetV3在CIFAR10数据集上的实现"></a>MobileNetV3在CIFAR10数据集上的实现</h5><h6 id="cifar-10数据集"><a href="#cifar-10数据集" class="headerlink" title="cifar-10数据集"></a>cifar-10数据集</h6><p>Cifar-10是由Hinton的学生Alex Krizhevsky、Ilya Sutskever收集的一个用于普适物体识别的计算机视觉数据集，它包含60000张32X32的RGB彩色图片，总共10个分类。其中，包括50000张用于训练集，10000张用于测试集。</p>
<p><img src="/essay/Cifar-10.png" alt="图片加载失败"></p>
<p>CIFAR-10数据集中一共包含10个类别的RGB彩色图片：飞机（airplane）、汽车（automobile）、鸟类（bird）、猫（cat）、鹿（deer）、狗（dog）、蛙类（frog）、马（horse）、船（ship）和卡车（truck）。</p>
<p>CIFAR-10是一个更接近普适物体的彩色图像数据集。与MNIST数据集相比，CIFAR-10具有以下不同点：</p>
<p>a) CIFAR-10 是3通道的彩色RGB图像，而MNIST是灰度图像。<br>b) CIFAR-10 的图片尺寸为32×32，而MNIST的图片尺寸为28×28，比MNIST稍大。</p>
<p>相比于手写字符，CIFAR-10含有的是现实世界中真实的物体，不仅噪声很大，而且物体的比例、特征都不尽相同，这为识别带来很大困难。直接的线性模型如Softmax在CIFAR-10上表现得很差。</p>
<h6 id="基于pytorch的代码实现"><a href="#基于pytorch的代码实现" class="headerlink" title="基于pytorch的代码实现"></a>基于pytorch的代码实现</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br></pre></td><td class="code"><pre><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from torchvision import datasets</span><br><span class="line">from torchvision.transforms import transforms</span><br><span class="line">from torchvision.transforms.transforms import ToTensor</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line"></span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import torch</span><br><span class="line">import datetime</span><br><span class="line"></span><br><span class="line">class hswish(nn.Module):</span><br><span class="line">    def __init__(self, inplace=True):</span><br><span class="line">        super(hswish, self).__init__()</span><br><span class="line">        self.inplace = inplace</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        f = nn.functional.relu6(x + 3., inplace=self.inplace) / 6.</span><br><span class="line">        <span class="built_in">return</span> x * f</span><br><span class="line"></span><br><span class="line">class hsigmoid(nn.Module):</span><br><span class="line">    def __init__(self, inplace=True):</span><br><span class="line">        super(hsigmoid, self).__init__()</span><br><span class="line">        self.inplace = inplace</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        f = nn.functional.relu6(x + 3., inplace=self.inplace) / 6.</span><br><span class="line">        <span class="built_in">return</span> f</span><br><span class="line"></span><br><span class="line">class SeModule(nn.Module):</span><br><span class="line">    def __init__(self, in_channels, se_ratio=0.25):</span><br><span class="line">        super(SeModule, self).__init__()</span><br><span class="line">        self.se_reduce = nn.Conv2d(in_channels, int(in_channels * se_ratio), kernel_size=1, stride=1, padding=0)</span><br><span class="line">        self.se_expand = nn.Conv2d(int(in_channels * se_ratio), in_channels, kernel_size=1, stride=1, padding=0)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        s = nn.functional.adaptive_avg_pool2d(x, 1)</span><br><span class="line">        s = self.se_expand(nn.functional.relu(self.se_reduce(s), inplace=True))</span><br><span class="line">        <span class="built_in">return</span> x * s.sigmoid()</span><br><span class="line"></span><br><span class="line">class ConvBlock(nn.Module):</span><br><span class="line">    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, <span class="built_in">groups</span>=1):</span><br><span class="line">        super(ConvBlock, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, <span class="built_in">groups</span>=<span class="built_in">groups</span>, bias=False)</span><br><span class="line">        self.bn = nn.BatchNorm2d(out_channels)</span><br><span class="line">        self.act = hswish()</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        <span class="built_in">return</span> self.act(self.bn(self.conv(x)))</span><br><span class="line"></span><br><span class="line">class SqueezeExcitation(nn.Module):</span><br><span class="line">    def __init__(self, in_channel, out_channel, reduction=4):</span><br><span class="line">        super(SqueezeExcitation, self).__init__()</span><br><span class="line">        self.pool = nn.AdaptiveAvgPool2d(1)</span><br><span class="line">        self.fc1 = nn.Conv2d(in_channel, out_channel // reduction, kernel_size=1, stride=1)</span><br><span class="line">        self.relu = nn.ReLU(inplace=True)</span><br><span class="line">        self.fc2 = nn.Conv2d(out_channel // reduction, out_channel, kernel_size=1, stride=1)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        out = self.pool(x)</span><br><span class="line">        out = self.fc1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.fc2(out)</span><br><span class="line">        out = self.sigmoid(out)</span><br><span class="line">        <span class="built_in">return</span> out</span><br><span class="line"></span><br><span class="line">class ResidualBlock(nn.Module):</span><br><span class="line">    def __init__(self, in_channels, out_channels, kernel_size, stride, use_se=True):</span><br><span class="line">        super(ResidualBlock, self).__init__()</span><br><span class="line">        self.conv1 = ConvBlock(in_channels, out_channels, kernel_size, stride, kernel_size // 2)</span><br><span class="line">        self.conv2 = ConvBlock(out_channels, out_channels, kernel_size, 1, kernel_size // 2)</span><br><span class="line">        self.use_se = use_se</span><br><span class="line">        <span class="keyword">if</span> use_se:</span><br><span class="line">            self.se = SqueezeExcitation(out_channels, out_channels)</span><br><span class="line">        self.shortcut = nn.Sequential()</span><br><span class="line">        <span class="keyword">if</span> stride != 1 or in_channels != out_channels:</span><br><span class="line">            self.shortcut = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),</span><br><span class="line">                nn.BatchNorm2d(out_channels)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        <span class="keyword">if</span> self.use_se:</span><br><span class="line">            out = out * self.se(out)</span><br><span class="line">        out += self.shortcut(x)</span><br><span class="line">        out = nn.functional.relu(out, inplace=True)</span><br><span class="line">        <span class="built_in">return</span> out</span><br><span class="line"></span><br><span class="line">class MobileNetV3Large(nn.Module):</span><br><span class="line">    def __init__(self, num_classes=1000):</span><br><span class="line">        super(MobileNetV3Large, self).__init__()  <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = ConvBlock(3, 16, 3, 2, 1)  <span class="comment"># 1/2</span></span><br><span class="line">        self.bottlenecks = nn.Sequential(</span><br><span class="line">            ResidualBlock(16, 16, 3, 1, False),</span><br><span class="line">            ResidualBlock(16, 24, 3, 2, False),  <span class="comment"># 1/4</span></span><br><span class="line">            ResidualBlock(24, 24, 3, 1, False),</span><br><span class="line">            ResidualBlock(24, 40, 5, 2, True),  <span class="comment"># 1/8</span></span><br><span class="line">            ResidualBlock(40, 40, 5, 1, True),</span><br><span class="line">            ResidualBlock(40, 40, 5, 1, True),</span><br><span class="line">            ResidualBlock(40, 80, 3, 2, False),  <span class="comment"># 1/16</span></span><br><span class="line">            ResidualBlock(80, 80, 3, 1, False),</span><br><span class="line">            ResidualBlock(80, 80, 3, 1, False),</span><br><span class="line">            ResidualBlock(80, 112, 5, 1, True),</span><br><span class="line">            ResidualBlock(112, 112, 5, 1, True),</span><br><span class="line">            ResidualBlock(112, 160, 5, 2, True),  <span class="comment"># 1/32</span></span><br><span class="line">            ResidualBlock(160, 160, 5, 1, True),</span><br><span class="line">            ResidualBlock(160, 160, 5, 1, True)</span><br><span class="line">        )</span><br><span class="line">        self.conv2 = ConvBlock(160, 960, 1, 1, 0)</span><br><span class="line">        self.pool = nn.AdaptiveAvgPool2d(1)</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(960, 1280),</span><br><span class="line">            nn.BatchNorm1d(1280),</span><br><span class="line">            nn.Hardswish(inplace=True),</span><br><span class="line">            nn.Linear(1280, num_classes),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bottlenecks(out)</span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.pool(out)</span><br><span class="line">        out = out.reshape(out.size(0), -1)</span><br><span class="line">        out = self.fc(out)</span><br><span class="line">        <span class="built_in">return</span> out</span><br><span class="line"></span><br><span class="line">class MobileNetV3Small(nn.Module):</span><br><span class="line">    def __init__(self, num_classes=1000):</span><br><span class="line">        super(MobileNetV3Small, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 = ConvBlock(3, 16, 3, 2, 1)  <span class="comment"># 1/2</span></span><br><span class="line">        self.bottlenecks = nn.Sequential(</span><br><span class="line">            ResidualBlock(16, 16, 3, 2, False),  <span class="comment"># 1/4</span></span><br><span class="line">            ResidualBlock(16, 72, 3, 2, False),  <span class="comment"># 1/8</span></span><br><span class="line">            ResidualBlock(72, 72, 3, 1, False),</span><br><span class="line">            ResidualBlock(72, 72, 3, 1, True),</span><br><span class="line">            ResidualBlock(72, 96, 3, 2, True),  <span class="comment"># 1/16</span></span><br><span class="line">            ResidualBlock(96, 96, 3, 1, True),</span><br><span class="line">            ResidualBlock(96, 96, 3, 1, True),</span><br><span class="line">            ResidualBlock(96, 240, 5, 2, True),  <span class="comment"># 1/32</span></span><br><span class="line">            ResidualBlock(240, 240, 5, 1, True),</span><br><span class="line">            ResidualBlock(240, 240, 5, 1, True),</span><br><span class="line">            ResidualBlock(240, 480, 5, 1, True),</span><br><span class="line">            ResidualBlock(480, 480, 5, 1, True),</span><br><span class="line">            ResidualBlock(480, 480, 5, 1, True),</span><br><span class="line">        )</span><br><span class="line">        self.conv2 = ConvBlock(480, 576, 1, 1, 0, <span class="built_in">groups</span>=2)</span><br><span class="line">        self.conv3 = nn.Conv2d(576, 1024, kernel_size=1, stride=1, padding=0, bias=False)</span><br><span class="line">        self.bn = nn.BatchNorm2d(1024)</span><br><span class="line">        self.act = hswish()</span><br><span class="line">        self.pool = nn.AdaptiveAvgPool2d(1)</span><br><span class="line">        self.fc = nn.Linear(1024, num_classes)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bottlenecks(out)</span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn(out)</span><br><span class="line">        out = self.act(out)</span><br><span class="line">        out = self.pool(out)</span><br><span class="line">        out = out.reshape(out.size(0), -1)</span><br><span class="line">        out = self.fc(out)</span><br><span class="line">        <span class="built_in">return</span> out</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([ToTensor(),</span><br><span class="line">                                transforms.Normalize(</span><br><span class="line">                                    mean=[0.5, 0.5, 0.5],</span><br><span class="line">                                    std=[0.5, 0.5, 0.5]</span><br><span class="line">                                ),</span><br><span class="line">                                transforms.Resize((<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">                                ])</span><br><span class="line"></span><br><span class="line">train_data = datasets.CIFAR10(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=True,</span><br><span class="line">    download=True,</span><br><span class="line">    transform=transform,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_data = datasets.CIFAR10(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=False,</span><br><span class="line">    download=True,</span><br><span class="line">    transform=transform,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">def get_format_time():</span><br><span class="line">    <span class="built_in">return</span> datetime.datetime.now().strftime(<span class="string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    batch_size = 64</span><br><span class="line">    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, drop_last=True)</span><br><span class="line">    test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True, drop_last=True)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    model = MobileNetV3Large(num_classes=10).to(device)</span><br><span class="line">    <span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line">    cross = nn.CrossEntropyLoss().to(device)</span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), 0.001)</span><br><span class="line"></span><br><span class="line">    train_loss = 0</span><br><span class="line">    train_accuracy = 0</span><br><span class="line">    epochs = 10</span><br><span class="line">    accuracy_rate = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">&#x27;&#123;get_format_time()&#125;, train epoch: &#123;epoch&#125;/&#123;epochs&#125;&#x27;</span>)</span><br><span class="line">        train_correct = 0</span><br><span class="line">        <span class="keyword">for</span> step, (images, labels) <span class="keyword">in</span> enumerate(train_loader, 0):</span><br><span class="line">            images, labels = images.to(device), labels.to(device)</span><br><span class="line">            outputs = model.forward(images)</span><br><span class="line">            train_loss = cross(outputs, labels)</span><br><span class="line">            train_loss.backward()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            predicted = torch.argmax(outputs, 1)</span><br><span class="line">            correct = torch.sum(predicted == labels)</span><br><span class="line">            train_correct += correct</span><br><span class="line"></span><br><span class="line">        train_accuracy = train_correct / len(train_data)</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">&quot;&#123;get_format_time()&#125;, loss:&#123;train_loss.item()&#125;, accuracy:&#123;train_accuracy&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line">        test_total = 0</span><br><span class="line">        test_correct = 0</span><br><span class="line">        test_loss = 0</span><br><span class="line">        with torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">                images, labels = images.to(device), labels.to(device)</span><br><span class="line">                outputs = model(images).to(device)</span><br><span class="line">                loss = cross(outputs, labels)</span><br><span class="line">                _, predicted = torch.max(outputs, 1)</span><br><span class="line">                test_total += labels.size(0)</span><br><span class="line">                test_correct += torch.sum(predicted == labels.data)</span><br><span class="line">                test_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        accuracy = 100 * test_correct / test_total</span><br><span class="line">        accuracy_rate.append(accuracy)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;, Train Loss is:&#123;:.4f&#125;, Train Accuracy is:&#123;:.4f&#125;%, Test Loss is::&#123;:.4f&#125; Test Accuracy is:&#123;:.4f&#125;%&quot;</span>.format(</span><br><span class="line">            get_format_time(),</span><br><span class="line">            train_loss / len(train_data),</span><br><span class="line">            100 * train_correct / len(train_data),</span><br><span class="line">            test_loss / len(test_data),</span><br><span class="line">            100 * test_correct / len(test_data)</span><br><span class="line">        ))</span><br></pre></td></tr></table></figure>

<h6 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h6><p><img src="/essay/%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C.png" alt="图片加载失败"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">2023-12-22 16:21:26, train epoch: 0/20</span><br><span class="line">2023-12-22 16:21:53, loss:1.077600359916687, accuracy:0.4221999943256378</span><br><span class="line">2023-12-22 16:21:58, Train Loss is:0.0000, Train Accuracy is:42.2200%, Test Loss is::0.0183 Test Accuracy is:57.5800%</span><br><span class="line">2023-12-22 16:21:58, train epoch: 1/20</span><br><span class="line">2023-12-22 16:22:22, loss:0.8761021494865417, accuracy:0.6502999663352966</span><br><span class="line">2023-12-22 16:22:27, Train Loss is:0.0000, Train Accuracy is:65.0300%, Test Loss is::0.0133 Test Accuracy is:69.8400%</span><br><span class="line">2023-12-22 16:22:27, train epoch: 2/20</span><br><span class="line">2023-12-22 16:23:03, loss:0.8734554648399353, accuracy:0.7473799586296082</span><br><span class="line">2023-12-22 16:23:10, Train Loss is:0.0000, Train Accuracy is:74.7380%, Test Loss is::0.0106 Test Accuracy is:76.7300%</span><br><span class="line">2023-12-22 16:23:10, train epoch: 3/20</span><br><span class="line">2023-12-22 16:23:56, loss:0.6179424524307251, accuracy:0.8049399852752686</span><br><span class="line">2023-12-22 16:24:04, Train Loss is:0.0000, Train Accuracy is:80.4940%, Test Loss is::0.0094 Test Accuracy is:79.2400%</span><br><span class="line">2023-12-22 16:24:04, train epoch: 4/20</span><br><span class="line">2023-12-22 16:24:50, loss:0.4694249629974365, accuracy:0.8365799784660339</span><br><span class="line">2023-12-22 16:24:58, Train Loss is:0.0000, Train Accuracy is:83.6580%, Test Loss is::0.0085 Test Accuracy is:81.5500%</span><br><span class="line">2023-12-22 16:24:58, train epoch: 5/20</span><br><span class="line">2023-12-22 16:25:44, loss:0.31567543745040894, accuracy:0.8552799820899963</span><br><span class="line">2023-12-22 16:25:52, Train Loss is:0.0000, Train Accuracy is:85.5280%, Test Loss is::0.0086 Test Accuracy is:81.5900%</span><br><span class="line">2023-12-22 16:25:52, train epoch: 6/20</span><br><span class="line">2023-12-22 16:26:38, loss:0.16210773587226868, accuracy:0.88646000623703</span><br><span class="line">2023-12-22 16:26:45, Train Loss is:0.0000, Train Accuracy is:88.6460%, Test Loss is::0.0077 Test Accuracy is:83.7600%</span><br><span class="line">2023-12-22 16:26:45, train epoch: 7/20</span><br><span class="line">2023-12-22 16:27:31, loss:0.3127828538417816, accuracy:0.9122599959373474</span><br><span class="line">2023-12-22 16:27:39, Train Loss is:0.0000, Train Accuracy is:91.2260%, Test Loss is::0.0079 Test Accuracy is:83.8300%</span><br><span class="line">2023-12-22 16:27:39, train epoch: 8/20</span><br><span class="line">2023-12-22 16:28:25, loss:0.26726457476615906, accuracy:0.9293599724769592</span><br><span class="line">2023-12-22 16:28:33, Train Loss is:0.0000, Train Accuracy is:92.9360%, Test Loss is::0.0085 Test Accuracy is:83.9400%</span><br><span class="line">2023-12-22 16:28:33, train epoch: 9/20</span><br><span class="line">2023-12-22 16:29:19, loss:0.2306433916091919, accuracy:0.9438599944114685</span><br><span class="line">2023-12-22 16:29:26, Train Loss is:0.0000, Train Accuracy is:94.3860%, Test Loss is::0.0093 Test Accuracy is:83.2100%</span><br><span class="line">2023-12-22 16:29:26, train epoch: 10/20</span><br><span class="line">2023-12-22 16:30:12, loss:0.13097506761550903, accuracy:0.9565799832344055</span><br><span class="line">2023-12-22 16:30:20, Train Loss is:0.0000, Train Accuracy is:95.6580%, Test Loss is::0.0107 Test Accuracy is:82.6900%</span><br><span class="line">2023-12-22 16:30:20, train epoch: 11/20</span><br><span class="line">2023-12-22 16:31:06, loss:0.06876415014266968, accuracy:0.962939977645874</span><br><span class="line">2023-12-22 16:31:14, Train Loss is:0.0000, Train Accuracy is:96.2940%, Test Loss is::0.0103 Test Accuracy is:83.4400%</span><br><span class="line">2023-12-22 16:31:14, train epoch: 12/20</span><br><span class="line">2023-12-22 16:32:00, loss:0.12005764991044998, accuracy:0.9681999683380127</span><br><span class="line">2023-12-22 16:32:07, Train Loss is:0.0000, Train Accuracy is:96.8200%, Test Loss is::0.0099 Test Accuracy is:84.0200%</span><br><span class="line">2023-12-22 16:32:07, train epoch: 13/20</span><br><span class="line">2023-12-22 16:32:53, loss:0.13355214893817902, accuracy:0.9756399989128113</span><br><span class="line">2023-12-22 16:33:00, Train Loss is:0.0000, Train Accuracy is:97.5640%, Test Loss is::0.0106 Test Accuracy is:84.5400%</span><br><span class="line">2023-12-22 16:33:00, train epoch: 14/20</span><br><span class="line">2023-12-22 16:33:46, loss:0.025063637644052505, accuracy:0.9772999882698059</span><br><span class="line">2023-12-22 16:33:54, Train Loss is:0.0000, Train Accuracy is:97.7300%, Test Loss is::0.0104 Test Accuracy is:85.0300%</span><br><span class="line">2023-12-22 16:33:54, train epoch: 15/20</span><br><span class="line">2023-12-22 16:34:40, loss:0.09421717375516891, accuracy:0.9760399460792542</span><br><span class="line">2023-12-22 16:34:48, Train Loss is:0.0000, Train Accuracy is:97.6040%, Test Loss is::0.0113 Test Accuracy is:84.1100%</span><br><span class="line">2023-12-22 16:34:48, train epoch: 16/20</span><br><span class="line">2023-12-22 16:35:35, loss:0.05912297964096069, accuracy:0.982479989528656</span><br><span class="line">2023-12-22 16:35:42, Train Loss is:0.0000, Train Accuracy is:98.2480%, Test Loss is::0.0115 Test Accuracy is:84.1600%</span><br><span class="line">2023-12-22 16:35:42, train epoch: 17/20</span><br><span class="line">2023-12-22 16:36:29, loss:0.023777423426508904, accuracy:0.9840799570083618</span><br><span class="line">2023-12-22 16:36:36, Train Loss is:0.0000, Train Accuracy is:98.4080%, Test Loss is::0.0127 Test Accuracy is:83.9600%</span><br><span class="line">2023-12-22 16:36:36, train epoch: 18/20</span><br><span class="line">2023-12-22 16:37:22, loss:0.05668738856911659, accuracy:0.984779953956604</span><br><span class="line">2023-12-22 16:37:30, Train Loss is:0.0000, Train Accuracy is:98.4780%, Test Loss is::0.0122 Test Accuracy is:84.5400%</span><br><span class="line">2023-12-22 16:37:30, train epoch: 19/20</span><br><span class="line">2023-12-22 16:38:16, loss:0.017958272248506546, accuracy:0.982759952545166</span><br><span class="line">2023-12-22 16:38:24, Train Loss is:0.0000, Train Accuracy is:98.2760%, Test Loss is::0.0113 Test Accuracy is:84.3800%</span><br><span class="line">2023-12-22 16:38:24,accuracy_rate=[57.672276 69.95193  76.85297  79.36699  81.68069  81.72076  83.89423</span><br><span class="line"> 83.96435  84.074524 83.34335  82.82252  83.57372  84.15465  84.67548</span><br><span class="line"> 85.16627  84.24479  84.294876 84.09455  84.67548  84.51523 ]</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h3><ol>
<li>爱因斯坦环在什么条件下会变成爱因斯坦十字？</li>
</ol>
<!-- comment -->
<script src="https://giscus.app/client.js"
        data-repo="fawninmyheart/blog_comment"
        data-repo-id="R_kgDOMh0eTw"
        data-category="Announcements"
        data-category-id="DIC_kwDOMh0eT84Chh6Y"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="zh-CN"
        crossorigin="anonymous"
        async>
</script>
      </div>
      
      
      
    </div>
    

    
    
    


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B0%9A%E8%AF%AD"><span class="nav-number">1.</span> <span class="nav-text">谚语</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%9F%E4%BF%A1"><span class="nav-number">2.</span> <span class="nav-text">生信</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#nginx"><span class="nav-number">3.</span> <span class="nav-text">nginx</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#snakemake"><span class="nav-number">4.</span> <span class="nav-text">snakemake</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#BUG"><span class="nav-number">4.1.</span> <span class="nav-text">BUG</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Git"><span class="nav-number">5.</span> <span class="nav-text">Git</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#commit-message-%E8%A7%84%E8%8C%83"><span class="nav-number">5.1.</span> <span class="nav-text">commit message 规范</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Header"><span class="nav-number">5.1.1.</span> <span class="nav-text">Header</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Git-commit%E5%B7%A5%E5%85%B7"><span class="nav-number">5.1.2.</span> <span class="nav-text">Git commit工具</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%87%8D%E3%80%81%E4%BA%BA%E7%89%A9%E8%AF%86%E5%88%AB%E3%80%81%E7%B3%BB%E5%88%97%E5%9B%BE%E7%89%87%E5%88%86%E7%BB%84"><span class="nav-number">6.</span> <span class="nav-text">图像去重、人物识别、系列图片分组</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9B%BE%E7%89%87%E5%8E%BB%E9%87%8D"><span class="nav-number">6.1.</span> <span class="nav-text">图片去重</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%BA%E7%89%A9%E8%AF%86%E5%88%AB"><span class="nav-number">6.2.</span> <span class="nav-text">人物识别</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91"><span class="nav-number">6.2.1.</span> <span class="nav-text">研究方向</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%B3%BB%E5%88%97%E5%9B%BE%E7%89%87%E5%88%86%E7%BB%84"><span class="nav-number">6.3.</span> <span class="nav-text">系列图片分组</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MobileNet"><span class="nav-number">6.4.</span> <span class="nav-text">MobileNet</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#MobileNet%E5%8F%91%E5%B1%95%E5%8F%B2"><span class="nav-number">6.4.1.</span> <span class="nav-text">MobileNet发展史</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MobileNet%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83"><span class="nav-number">6.4.2.</span> <span class="nav-text">MobileNet模型比较</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MobileNetV3%E5%9C%A8CIFAR10%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">6.4.3.</span> <span class="nav-text">MobileNetV3在CIFAR10数据集上的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#cifar-10%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">6.4.3.1.</span> <span class="nav-text">cifar-10数据集</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8Epytorch%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="nav-number">6.4.3.2.</span> <span class="nav-text">基于pytorch的代码实现</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C"><span class="nav-number">6.4.3.3.</span> <span class="nav-text">运行结果</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%96%91%E9%97%AE"><span class="nav-number">7.</span> <span class="nav-text">疑问</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Shen Hua"
      src="/images/xiaohu.jpg">
  <p class="site-author-name" itemprop="name">Shen Hua</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">6</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fawninmyheart" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fawninmyheart" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:shenhua0326@qq.com" title="E-Mail → mailto:shenhua0326@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Shen Hua</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
